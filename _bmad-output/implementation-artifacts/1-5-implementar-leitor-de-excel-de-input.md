# Story 1.5: Implementar Leitor de Excel de Input

Status: done

<!-- Note: Validation is optional. Run validate-create-story for quality check before dev-story. -->

## Story

Como Rodrigo,
Eu quero importar um Excel de input com temas, focos e per√≠odos,
Para que o sistema possa processar os dados estruturados e gerar quest√µes (FR1, FR2).

## Acceptance Criteria

**Given** que tenho um arquivo Excel com colunas tema, foco, periodo
**When** executo ExcelReader.read_input(file_path) em src/construtor/io/excel_reader.py
**Then** o sistema l√™ o Excel usando pandas + openpyxl
**And** valida que as colunas obrigat√≥rias (tema, foco, periodo) existem
**And** valida que periodo cont√©m apenas valores v√°lidos (1¬∫ ano, 2¬∫ ano, 3¬∫ ano, 4¬∫ ano)
**And** valida que n√£o h√° linhas com dados faltantes nas colunas obrigat√≥rias
**And** retorna uma lista de objetos Pydantic FocoInput(tema: str, foco: str, periodo: str)
**And** se a valida√ß√£o falhar, lan√ßa ValidationError com mensagem clara indicando qual coluna/linha tem problema
**And** se o arquivo n√£o existir, lan√ßa FileNotFoundError
**And** se o formato n√£o for Excel v√°lido, lan√ßa OutputParsingError
**And** logs estruturados s√£o gerados com INFO para sucesso, ERROR para falhas

## Tasks / Subtasks

### Task 1: Design FocoInput Pydantic Model (AC: #5)
- [x] Create or verify FocoInput model in src/construtor/models/question.py
- [x] Define fields: tema (str), foco (str), periodo (str)
- [x] Add Field validators with descriptions
- [x] Add validator for periodo (must be in ['1¬∫ ano', '2¬∫ ano', '3¬∫ ano', '4¬∫ ano'])
- [x] Use ConfigDict(strict=True) for type enforcement
- [x] Add docstring with example usage

### Task 2: Implement Core Excel Reading (AC: #1, #2)
- [x] Create ExcelReader class in src/construtor/io/excel_reader.py
- [x] Implement read_input(file_path: str) method
- [x] Use pandas.read_excel() with engine='openpyxl'
- [x] Handle file path validation (check if file exists)
- [x] Detect and handle BOM (byte order mark) if present - pandas handles BOM implicitly when reading Excel files
- [x] Handle Excel file format validation (catch openpyxl exceptions)
- [x] Validate file extension (.xlsx/.xlsm only)
- [x] Log INFO when file is successfully loaded

### Task 3: Implement Column Validation (AC: #3)
- [x] Check that required columns exist: ['tema', 'foco', 'periodo']
- [x] Handle case-insensitive column name matching
- [x] Handle columns with extra whitespace (strip names)
- [x] If columns missing, raise ValidationError with clear message
- [x] List which columns are missing in error message
- [x] Log ERROR with missing column details

### Task 4: Implement Periodo Validation (AC: #4)
- [x] Define VALID_PERIODOS constant = ['1¬∫ ano', '2¬∫ ano', '3¬∫ ano', '4¬∫ ano']
- [x] Check all values in 'periodo' column against VALID_PERIODOS
- [x] Handle case variations (normalize to expected format)
- [x] Collect all invalid values and row numbers
- [x] If invalid values found, raise ValidationError with row numbers and invalid values
- [x] Log ERROR with invalid periodo details

### Task 5: Implement Missing Data Validation (AC: #5)
- [x] Use pandas.isna() or .notna() to detect missing values
- [x] Check for missing values in required columns (tema, foco, periodo)
- [x] Collect row numbers with missing data per column
- [x] If missing data found, raise ValidationError with row/column details
- [x] Handle edge cases: empty strings, whitespace-only values
- [x] Log ERROR with missing data details

### Task 6: Convert DataFrame to Pydantic Models (AC: #5)
- [x] Iterate over validated DataFrame rows
- [x] Create FocoInput instance for each row
- [x] Use model_validate() for Pydantic validation per row
- [x] Catch ValidationError from Pydantic and re-raise with row number
- [x] Return List[FocoInput]
- [x] Log INFO with count of successfully parsed focos

### Task 7: Implement Comprehensive Error Handling (AC: #6, #7, #8)
- [x] Catch FileNotFoundError if file doesn't exist
- [x] Re-raise FileNotFoundError with clear message including file path
- [x] Catch openpyxl exceptions for invalid Excel format
- [x] Raise OutputParsingError for Excel format issues
- [x] Catch all pandas exceptions (e.g., PermissionError)
- [x] Ensure all exceptions include context (file path, row number if applicable)
- [x] Log all errors with ERROR level before raising

### Task 8: Implement Structured Logging (AC: #9)
- [x] Import logging and create logger = logging.getLogger(__name__)
- [x] Log INFO: "Loading Excel from {file_path}"
- [x] Log INFO: "Successfully loaded {count} focos from Excel"
- [x] Log ERROR: "File not found: {file_path}" if FileNotFoundError
- [x] Log ERROR: "Invalid Excel format: {error}" if format error
- [x] Log ERROR: "Missing columns: {missing_cols}" if validation fails
- [x] Log ERROR: "Invalid periodo values at rows {rows}: {values}"
- [x] Log ERROR: "Missing data in column {col} at rows {rows}"

### Task 9: Create Comprehensive Tests
- [x] Create tests/test_io/test_excel_reader.py
- [x] Test successful reading of valid Excel file
- [x] Test column validation (missing columns)
- [x] Test periodo validation (invalid values)
- [x] Test missing data detection (empty cells)
- [x] Test FileNotFoundError for non-existent file
- [x] Test OutputParsingError for invalid Excel format
- [x] Test case-insensitive column matching
- [x] Test whitespace handling in column names
- [x] Test whitespace-only values treated as missing
- [x] Test FocoInput creation from DataFrame rows
- [x] Create sample Excel files in tests/fixtures/ for testing

### Task 10: Quality Validation
- [x] Run `uv run ruff check src/construtor/io/` and fix all warnings
- [x] Run `uv run ruff format src/construtor/io/` for formatting
- [x] Run `uv run pytest tests/test_io/` and verify 100% pass
- [x] Verify imports: `from construtor.io import ExcelReader`
- [x] Check snake_case naming throughout
- [x] Verify type hints on all public methods
- [x] Verify docstrings with Args/Returns/Raises

## Dev Notes

### Context & Business Value

Esta √© a **Story 1.5** - a quinta hist√≥ria do Epic 1. Esta story cria o **leitor de Excel de input** que permite Rodrigo importar os temas, focos e per√≠odos acad√™micos que servir√£o como base para gerar as ~8.000 quest√µes m√©dicas necess√°rias.

### Import√¢ncia Cr√≠tica

**Por que esta Story √© CR√çTICA:**
1. **Gateway do Pipeline:** √â o ponto de entrada de TODOS os dados - se o Excel n√£o for lido corretamente, TODO o pipeline falha
2. **Valida√ß√£o Antecipada:** Detectar problemas no Excel ANTES de iniciar produ√ß√£o em massa economiza horas de processamento e d√≥lares em chamadas API
3. **Integridade de Dados:** Valida√ß√£o de per√≠odo acad√™mico (1¬∫-4¬∫ ano) previne quest√µes inadequadas ao p√∫blico-alvo
4. **Funda√ß√£o do Epic 2:** O pipeline de gera√ß√£o de quest√µes depende de FocoInput bem estruturado
5. **Conformidade FR1-FR2:** Requisitos funcionais fundamentais do produto

**ERROS COMUNS A PREVENIR:**
- ‚ùå **N√£o validar colunas** ‚Üí Pipeline crasheia quando tenta acessar coluna inexistente em meio a processamento
- ‚ùå **Aceitar dados faltantes silenciosamente** ‚Üí Quest√µes geradas sem tema/foco resultam em output inv√°lido
- ‚ùå **N√£o normalizar per√≠odo acad√™mico** ‚Üí "1 ano", "primeiro ano", "1¬∫ Ano" n√£o s√£o detectados como inv√°lidos
- ‚ùå **Mensagens de erro vagas** ‚Üí "Erro ao ler Excel" n√£o ajuda Rodrigo a corrigir o problema
- ‚ùå **N√£o logar informa√ß√µes** ‚Üí Imposs√≠vel debugar qual linha do Excel causou problema
- ‚ùå **Assumir encoding UTF-8** ‚Üí Excel brasileiro pode ter BOM ou Latin-1, quebrando leitura
- ‚ùå **N√£o testar com Excel real** ‚Üí Testes com CSV n√£o detectam problemas de formata√ß√£o Excel

### Impacto no Neg√≥cio

- **Preven√ß√£o de Desperd√≠cio:** Valida√ß√£o antecipada evita processar milhares de quest√µes de dados inv√°lidos (economia de tempo e custo API)
- **Prazo Garantido:** Feedback imediato sobre problemas no Excel permite corre√ß√£o r√°pida (deadline 14/02/2026 √© apertado)
- **Qualidade Assegurada:** Valida√ß√£o de per√≠odo garante que quest√µes s√£o adequadas ao ano acad√™mico correto
- **Experi√™ncia do Usu√°rio:** Mensagens de erro claras ("Coluna 'periodo' tem valor inv√°lido '5¬∫ ano' na linha 42") permitem corre√ß√£o eficiente

### Depend√™ncias

**Bloqueado Por:**
- ‚úÖ Story 1.1 (estrutura do projeto) - COMPLETADA
- ‚úÖ Story 1.2 (modelos Pydantic) - COMPLETADA - Fornece FocoInput model
- ‚ö†Ô∏è Story 1.4 (SQLite persistence) - COMPLETADA - ExcelReader n√£o depende diretamente, mas pipeline futuro usar√° ambos

**Bloqueia:**
- Story 1.6 (Excel Writer) - padr√µes de pandas/openpyxl estabelecidos aqui s√£o reutilizados
- Story 2.1 (Gerador de Sub-focos) - consome List[FocoInput] produzida por esta story
- Story 3.1 (Batch Processor) - l√™ focos do Excel via ExcelReader
- Todo o pipeline de gera√ß√£o - sem input v√°lido, nada funciona

### M√©tricas de Sucesso

- ‚úÖ Excel v√°lido com 100+ focos √© lido em <1 segundo
- ‚úÖ Colunas obrigat√≥rias validadas: erro claro se 'tema', 'foco' ou 'periodo' estiverem faltando
- ‚úÖ Valores de per√≠odo validados: apenas '1¬∫ ano', '2¬∫ ano', '3¬∫ ano', '4¬∫ ano' aceitos
- ‚úÖ Dados faltantes detectados: lista de linhas com c√©lulas vazias
- ‚úÖ FileNotFoundError com path completo se arquivo n√£o existe
- ‚úÖ OutputParsingError se arquivo n√£o √© Excel v√°lido (.xlsx)
- ‚úÖ Logs INFO/ERROR estruturados para todas as opera√ß√µes
- ‚úÖ FocoInput Pydantic models retornados com valida√ß√£o autom√°tica
- ‚úÖ `ruff check` passa com zero warnings
- ‚úÖ 100% cobertura de testes (m√≠nimo 11 tests)

### Enhancement: Opcional - Coluna sub_foco Manual

**Nota sobre Design:**

O AC original n√£o menciona coluna `sub_foco`, mas a arquitetura prev√™ FR3: "Rodrigo pode definir se sub-focos s√£o gerados pela IA ou fornecidos manualmente". Para Story 1.5 (MVP), vamos **ignorar** a coluna `sub_foco` mesmo se presente no Excel, pois:

1. Story 2.1 (Gerador de Sub-focos) gera sub-focos automaticamente via IA
2. Modo manual de sub-focos √© feature opcional (pode ser Epic 2 story adicional)
3. ExcelReader foca no m√≠nimo vi√°vel: tema + foco + periodo

**Implementa√ß√£o Recomendada:**
- Ler apenas colunas obrigat√≥rias: `tema`, `foco`, `periodo`
- Ignorar outras colunas presentes no Excel (n√£o validar, n√£o retornar erro)
- Se no futuro precisar de sub_foco manual, adicionar como campo opcional em FocoInput

## Technical Requirements

### Core Technologies

| Tecnologia | Vers√£o | Prop√≥sito | Documenta√ß√£o |
|-----------|---------|-----------|--------------|
| **pandas** | 3.0.0+ | Leitura e manipula√ß√£o de dados tabulares | [pandas.read_excel](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html) |
| **openpyxl** | 3.1.5+ | Backend para pandas ler/escrever .xlsx | [openpyxl Docs](https://openpyxl.readthedocs.io/) |
| **Pydantic** | 2.10.4+ | Valida√ß√£o de FocoInput ap√≥s leitura | [Pydantic Docs](https://docs.pydantic.dev/) |
| **pathlib** | Python 3.11+ stdlib | Manipula√ß√£o de paths cross-platform | [Pathlib Docs](https://docs.python.org/3/library/pathlib.html) |

### Pandas read_excel() Latest Best Practices (2026)

**Basic Usage Pattern:**
```python
import pandas as pd
from pathlib import Path

# ALWAYS use engine='openpyxl' for .xlsx files (explicit is better)
df = pd.read_excel(
    "data/input.xlsx",
    engine='openpyxl',
    sheet_name=0,           # First sheet (default)
    header=0,               # First row as column names (default)
    dtype=str,              # Read all columns as strings (prevents Excel number conversion)
    na_filter=True,         # Detect missing values (default)
    keep_default_na=True,   # Use default NaN markers (default)
)
```

**Critical Parameters for Our Use Case:**

1. **engine='openpyxl'** - Explicit backend (pandas 3.0 requires this for .xlsx)
2. **dtype=str** - Read all columns as strings to prevent Excel auto-conversion (e.g., "1¬∫ ano" ‚Üí number)
3. **na_filter=True** - Detect missing values (default behavior, but explicit is better)
4. **usecols=['tema', 'foco', 'periodo']** - Read only required columns (performance optimization)

**Missing Value Detection:**

Pandas 3.0 recognizes these as NaN by default:
- Empty strings: `''`
- Excel NA markers: `'#N/A'`, `'#N/A N/A'`, `'#NA'`
- Common NA values: `'N/A'`, `'NA'`, `'NULL'`, `'NaN'`, `'None'`, `'null'`

**Custom NA Values (if needed):**
```python
df = pd.read_excel(
    "input.xlsx",
    engine='openpyxl',
    na_values=['vazio', 'sem dado'],  # Add custom Portuguese NA markers
    keep_default_na=True,              # Keep default + custom
)
```

### openpyxl 3.1.5+ Integration

**Why openpyxl 3.1.5 (Latest 2026):**
- Requires Python 3.8+ (we have 3.11, perfect)
- Performance improvements for large files (15-20% faster than 3.0.x)
- Better error handling for corrupted Excel files
- Full support for .xlsx format (not .xls - that's xlrd)

**Pandas Uses openpyxl as Backend:**

You don't import openpyxl directly in most cases - pandas handles it internally:

```python
# ‚úÖ CORRECT: pandas with openpyxl engine
import pandas as pd
df = pd.read_excel("input.xlsx", engine='openpyxl')

# ‚ùå WRONG: Don't load openpyxl directly unless you need advanced features
import openpyxl
wb = openpyxl.load_workbook("input.xlsx")  # Only if you need cell formatting, charts, etc.
```

**When to Use openpyxl Directly:**
- Need cell formatting (bold, colors, etc.)
- Need to read charts or images
- Need granular control over Excel structures

**For This Story:** Use pandas with engine='openpyxl' - NO direct openpyxl imports needed.

### Validation Patterns

**1. Column Existence Validation:**
```python
required_columns = {'tema', 'foco', 'periodo'}
actual_columns = set(df.columns.str.strip().str.lower())  # Normalize

missing = required_columns - actual_columns
if missing:
    raise ValidationError(f"Missing required columns: {missing}")
```

**2. Periodo Validation:**
```python
VALID_PERIODOS = ['1¬∫ ano', '2¬∫ ano', '3¬∫ ano', '4¬∫ ano']

# Check all values
invalid_rows = df[~df['periodo'].isin(VALID_PERIODOS)]
if not invalid_rows.empty:
    # Collect row numbers (1-indexed for Excel) and invalid values
    errors = [(idx + 2, row['periodo']) for idx, row in invalid_rows.iterrows()]
    raise ValidationError(f"Invalid periodo values: {errors}")
```

**3. Missing Data Detection:**
```python
# Check for NaN in required columns
for col in ['tema', 'foco', 'periodo']:
    missing_rows = df[df[col].isna()]
    if not missing_rows.empty:
        row_numbers = [idx + 2 for idx in missing_rows.index]  # +2 for Excel (header + 0-index)
        raise ValidationError(f"Missing data in column '{col}' at rows: {row_numbers}")
```

**4. Whitespace Handling:**
```python
# Strip whitespace from all string columns
df['tema'] = df['tema'].str.strip()
df['foco'] = df['foco'].str.strip()
df['periodo'] = df['periodo'].str.strip()

# Treat whitespace-only as missing
df.replace(r'^\s*$', pd.NA, regex=True, inplace=True)
```

### Error Handling Patterns

**File Not Found:**
```python
from pathlib import Path
from construtor.config.exceptions import ValidationError

def read_input(self, file_path: str) -> List[FocoInput]:
    path = Path(file_path)

    if not path.exists():
        raise FileNotFoundError(f"Excel file not found: {file_path}")

    if not path.is_file():
        raise FileNotFoundError(f"Path is not a file: {file_path}")
```

**Invalid Excel Format:**
```python
from openpyxl.utils.exceptions import InvalidFileException
from construtor.config.exceptions import OutputParsingError

try:
    df = pd.read_excel(file_path, engine='openpyxl')
except InvalidFileException as e:
    raise OutputParsingError(f"Invalid Excel format: {file_path}") from e
except Exception as e:
    raise OutputParsingError(f"Failed to read Excel: {e}") from e
```

**Pandas Exceptions:**
```python
import pandas as pd

try:
    df = pd.read_excel(file_path, engine='openpyxl')
except pd.errors.EmptyDataError:
    raise ValidationError("Excel file is empty")
except pd.errors.ParserError as e:
    raise OutputParsingError(f"Excel parsing failed: {e}") from e
```

### Pydantic Integration

**FocoInput Model (should exist in models/question.py):**
```python
from pydantic import BaseModel, Field, field_validator, ConfigDict
from typing import Literal

class FocoInput(BaseModel):
    """Input data for a single foco (focus topic) from Excel."""

    model_config = ConfigDict(strict=True)

    tema: str = Field(..., description="Tema m√©dico (ex: Cardiologia)")
    foco: str = Field(..., description="Foco espec√≠fico dentro do tema (ex: Insufici√™ncia Card√≠aca)")
    periodo: Literal['1¬∫ ano', '2¬∫ ano', '3¬∫ ano', '4¬∫ ano'] = Field(
        ...,
        description="Per√≠odo acad√™mico alvo (1¬∫ a 4¬∫ ano de medicina)"
    )

    @field_validator('periodo')
    @classmethod
    def validate_periodo(cls, v: str) -> str:
        """Validate periodo is one of the allowed academic periods."""
        allowed = ['1¬∫ ano', '2¬∫ ano', '3¬∫ ano', '4¬∫ ano']
        if v not in allowed:
            raise ValueError(f"periodo must be one of {allowed}, got '{v}'")
        return v

    @field_validator('tema', 'foco')
    @classmethod
    def validate_non_empty(cls, v: str) -> str:
        """Validate string fields are non-empty."""
        if not v or v.isspace():
            raise ValueError("Field cannot be empty or whitespace")
        return v.strip()
```

**DataFrame to Pydantic Conversion:**
```python
from pydantic import ValidationError as PydanticValidationError
from construtor.config.exceptions import ValidationError

def _dataframe_to_focos(self, df: pd.DataFrame) -> List[FocoInput]:
    """Convert validated DataFrame to list of FocoInput models."""
    focos = []

    for idx, row in df.iterrows():
        try:
            foco = FocoInput(
                tema=row['tema'],
                foco=row['foco'],
                periodo=row['periodo'],
            )
            focos.append(foco)
        except PydanticValidationError as e:
            row_num = idx + 2  # Excel row number (header + 0-index)
            raise ValidationError(f"Validation failed at row {row_num}: {e}") from e

    return focos
```

### Performance Considerations

**For MVP (~100-500 focos):**
- No optimization needed - pandas handles this trivially (<100ms)
- Full file read is fine (no chunking required)

**For Scale (if Excel grows to thousands of rows):**
```python
# Read only required columns (saves memory)
df = pd.read_excel(
    file_path,
    engine='openpyxl',
    usecols=['tema', 'foco', 'periodo'],  # Only load these
)

# If file is HUGE (10k+ rows), use chunks
chunks = pd.read_excel(
    file_path,
    engine='openpyxl',
    chunksize=1000,  # Process 1000 rows at a time
)
for chunk in chunks:
    # Process each chunk
    pass
```

**For This Story:** Simple full-file read is sufficient. No chunking needed.

## Architecture Compliance

### Naming Conventions (CRITICAL - Must Follow Exactly)

**Fonte:** [Architecture Doc - Naming Patterns](../../_bmad-output/planning-artifacts/architecture.md#naming-patterns)

| Elemento | Conven√ß√£o | Exemplos | Idioma |
|---------|-----------|----------|--------|
| **M√≥dulo/arquivo** | snake_case | `excel_reader.py` | Ingl√™s |
| **Classes** | PascalCase | `ExcelReader`, `FocoInput` | Ingl√™s |
| **M√©todos** | snake_case | `read_input()`, `_validate_columns()` | Ingl√™s |
| **Vari√°veis** | snake_case | `file_path`, `df`, `focos` | Ingl√™s |
| **Constantes** | UPPER_SNAKE_CASE | `VALID_PERIODOS`, `REQUIRED_COLUMNS` | Ingl√™s |
| **Campos Pydantic (dom√≠nio)** | snake_case | `tema`, `foco`, `periodo` | **Portugu√™s** |

**IMPORTANTE:** Campos do modelo FocoInput (tema, foco, periodo) devem estar em PORTUGU√äS para consist√™ncia com Excel de output (26 colunas) e QuestionRecord.

### Mandatory Patterns from Architecture

**Fonte:** [Architecture Doc - Process Patterns](../../_bmad-output/planning-artifacts/architecture.md#process-patterns)

**1. Exception Hierarchy (MUST USE):**
```python
from construtor.config.exceptions import (
    PipelineError,
    ValidationError,      # For validation failures (missing columns, invalid periodo, etc.)
    OutputParsingError,   # For Excel format issues
)

# ‚úÖ CORRECT: Use specific exceptions
if missing_columns:
    raise ValidationError(f"Missing columns: {missing_columns}")

# ‚ùå WRONG: Never use bare Exception
if missing_columns:
    raise Exception("Error")  # DON'T DO THIS
```

**2. Logging Pattern (MUST FOLLOW):**
```python
import logging
logger = logging.getLogger(__name__)

# ‚úÖ CORRECT: Structured logging with context
logger.info(f"Loading Excel from {file_path}")
logger.info(f"Successfully loaded {len(focos)} focos from {file_path}")
logger.error(f"Missing columns {missing} in {file_path}")

# ‚ùå WRONG: No logging or print statements
print("Loading file...")  # DON'T DO THIS
```

**Log Levels:**
- `INFO` - File loaded successfully, number of focos parsed
- `ERROR` - File not found, validation errors, parsing errors

**3. Type Hints (MANDATORY):**
```python
from pathlib import Path
from typing import List
from construtor.models import FocoInput

# ‚úÖ CORRECT: Full type hints
def read_input(self, file_path: str) -> List[FocoInput]:
    """Read and validate Excel input file."""
    pass

# ‚ùå WRONG: No type hints
def read_input(self, file_path):  # DON'T DO THIS
    pass
```

**4. Docstrings (MANDATORY - Google Style):**
```python
def read_input(self, file_path: str) -> List[FocoInput]:
    """
    Read and validate Excel input file with temas, focos, and periodos.

    Args:
        file_path: Path to Excel file (.xlsx format)

    Returns:
        List of validated FocoInput objects

    Raises:
        FileNotFoundError: If file doesn't exist
        ValidationError: If columns missing, periodo invalid, or data missing
        OutputParsingError: If Excel format is invalid

    Example:
        >>> reader = ExcelReader()
        >>> focos = reader.read_input("data/input.xlsx")
        >>> print(len(focos))
        156
    """
```

### Anti-Patterns (STRICTLY FORBIDDEN)

**Fonte:** [Architecture Doc - Anti-Patterns](../../_bmad-output/planning-artifacts/architecture.md#anti-patterns-proibidos)

```python
# ‚ùå ANTI-PATTERN 1: Using bare except
try:
    df = pd.read_excel(file_path)
except:  # DON'T DO THIS
    print("Error")

# ‚úÖ CORRECT: Specific exception handling
try:
    df = pd.read_excel(file_path, engine='openpyxl')
except FileNotFoundError:
    raise
except Exception as e:
    raise OutputParsingError(f"Failed to read Excel: {e}") from e


# ‚ùå ANTI-PATTERN 2: Vague error messages
if validation_failed:
    raise ValidationError("Invalid data")  # DON'T DO THIS

# ‚úÖ CORRECT: Specific error messages with context
if missing_columns:
    raise ValidationError(
        f"Missing required columns: {missing_columns}. "
        f"Expected: tema, foco, periodo. Found: {list(df.columns)}"
    )


# ‚ùå ANTI-PATTERN 3: Silently ignoring errors
df['periodo'] = df['periodo'].fillna('1¬∫ ano')  # DON'T DO THIS - masks problems

# ‚úÖ CORRECT: Explicit validation with clear errors
if df['periodo'].isna().any():
    missing_rows = df[df['periodo'].isna()].index + 2
    raise ValidationError(f"Missing periodo at rows: {list(missing_rows)}")


# ‚ùå ANTI-PATTERN 4: Using print instead of logging
print("Loading file...")  # DON'T DO THIS

# ‚úÖ CORRECT: Structured logging
logger.info(f"Loading Excel from {file_path}")
```

## Library & Framework Requirements

### pandas 3.0.0+ (Latest 2026)

**Installation:** Already in dependencies via Story 1.1

**Key Imports:**
```python
import pandas as pd
from pandas import DataFrame
```

**Critical Features for This Story:**
- `pd.read_excel()` - Main entry point
- `engine='openpyxl'` - MUST specify for .xlsx files
- `df.isna()` - Detect missing values
- `df.columns` - Access column names
- `df.iterrows()` - Iterate over rows for Pydantic conversion

**Latest Best Practice (2026):**

Pandas 3.0 uses Apache Arrow backend for better performance, but for Excel I/O, openpyxl is still the standard engine.

```python
# ‚úÖ CORRECT: Explicit engine
df = pd.read_excel("input.xlsx", engine='openpyxl', dtype=str)

# ‚ö†Ô∏è AVOID: Implicit engine (works but not explicit)
df = pd.read_excel("input.xlsx")
```

**Sources:**
- [pandas.read_excel Documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html)

### openpyxl 3.1.5+ (Latest 2026)

**Installation:** Already in dependencies via Story 1.1

**Role:** Backend for pandas.read_excel() - NO direct imports needed for this story.

**When pandas Calls openpyxl:**
```python
df = pd.read_excel("input.xlsx", engine='openpyxl')
# Behind the scenes:
# 1. pandas loads openpyxl
# 2. openpyxl opens .xlsx file
# 3. openpyxl parses XML structure
# 4. pandas converts to DataFrame
```

**Performance (openpyxl 3.1.5):**
- 15-20% faster than 3.0.x
- Better memory efficiency for large files
- Improved error messages for corrupted files

**Sources:**
- [openpyxl Documentation](https://openpyxl.readthedocs.io/en/stable/)

### Pydantic Integration

**Model Location:** `src/construtor/models/question.py`

**Expected Model:**
```python
from pydantic import BaseModel, Field, field_validator, ConfigDict
from typing import Literal

class FocoInput(BaseModel):
    """Input data from Excel row - one foco to generate sub-focos from."""

    model_config = ConfigDict(strict=True)

    tema: str = Field(..., description="Medical theme (e.g., Cardiologia)")
    foco: str = Field(..., description="Specific focus within theme")
    periodo: Literal['1¬∫ ano', '2¬∫ ano', '3¬∫ ano', '4¬∫ ano'] = Field(
        ..., description="Target academic period"
    )
```

**If FocoInput doesn't exist yet:** Create it in models/question.py as part of this story.

### Testing Dependencies

**pytest Fixtures for Excel Testing:**
```python
import pytest
import pandas as pd
from pathlib import Path

@pytest.fixture
def temp_excel_file(tmp_path):
    """Create temporary valid Excel file for testing."""
    df = pd.DataFrame({
        'tema': ['Cardiologia', 'Pneumologia'],
        'foco': ['Insufici√™ncia Card√≠aca', 'Asma'],
        'periodo': ['3¬∫ ano', '2¬∫ ano'],
    })

    file_path = tmp_path / "test_input.xlsx"
    df.to_excel(file_path, index=False, engine='openpyxl')
    return file_path

@pytest.fixture
def invalid_excel_file(tmp_path):
    """Create Excel file with invalid periodo values."""
    df = pd.DataFrame({
        'tema': ['Cardiologia'],
        'foco': ['ICC'],
        'periodo': ['5¬∫ ano'],  # Invalid!
    })

    file_path = tmp_path / "invalid.xlsx"
    df.to_excel(file_path, index=False, engine='openpyxl')
    return file_path
```

## File Structure Requirements

### Files to Create

```
src/construtor/io/
‚îú‚îÄ‚îÄ __init__.py                    # Export ExcelReader
‚îî‚îÄ‚îÄ excel_reader.py                # ExcelReader implementation

tests/test_io/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ test_excel_reader.py           # Comprehensive tests (11+ tests)
‚îî‚îÄ‚îÄ fixtures/                      # Sample Excel files for testing
    ‚îú‚îÄ‚îÄ valid_input.xlsx           # Valid Excel with 3+ rows
    ‚îú‚îÄ‚îÄ missing_columns.xlsx       # Missing 'periodo' column
    ‚îú‚îÄ‚îÄ invalid_periodo.xlsx       # Has '5¬∫ ano' value
    ‚îî‚îÄ‚îÄ missing_data.xlsx          # Empty cells in required columns
```

### ExcelReader Public API

```python
from pathlib import Path
from typing import List
from construtor.models import FocoInput

class ExcelReader:
    """Excel input file reader with validation."""

    REQUIRED_COLUMNS = ['tema', 'foco', 'periodo']
    VALID_PERIODOS = ['1¬∫ ano', '2¬∫ ano', '3¬∫ ano', '4¬∫ ano']

    def read_input(self, file_path: str) -> List[FocoInput]:
        """
        Read and validate Excel input file.

        Args:
            file_path: Path to Excel file (.xlsx)

        Returns:
            List of validated FocoInput objects

        Raises:
            FileNotFoundError: If file doesn't exist
            ValidationError: If validation fails
            OutputParsingError: If Excel format invalid
        """
        ...

    def _validate_file_exists(self, path: Path) -> None:
        """Validate file exists and is readable."""
        ...

    def _validate_columns(self, df: DataFrame) -> None:
        """Validate required columns exist."""
        ...

    def _validate_periodo_values(self, df: DataFrame) -> None:
        """Validate all periodo values are valid."""
        ...

    def _validate_no_missing_data(self, df: DataFrame) -> None:
        """Validate no missing data in required columns."""
        ...

    def _dataframe_to_focos(self, df: DataFrame) -> List[FocoInput]:
        """Convert DataFrame to list of FocoInput models."""
        ...
```

## Testing Requirements

### Test Coverage Checklist

**tests/test_io/test_excel_reader.py deve incluir:**

1. **Happy Path Tests (3 tests)**
   - [ ] Test reading valid Excel with multiple rows
   - [ ] Test FocoInput objects created correctly
   - [ ] Test all fields populated from Excel columns

2. **Column Validation Tests (3 tests)**
   - [ ] Test error when 'tema' column missing
   - [ ] Test error when 'foco' column missing
   - [ ] Test error when 'periodo' column missing

3. **Periodo Validation Tests (2 tests)**
   - [ ] Test error for invalid periodo value ('5¬∫ ano')
   - [ ] Test all valid periodos accepted ('1¬∫ ano', '2¬∫ ano', '3¬∫ ano', '4¬∫ ano')

4. **Missing Data Tests (3 tests)**
   - [ ] Test error when 'tema' has empty cell
   - [ ] Test error when 'foco' has empty cell
   - [ ] Test error when 'periodo' has empty cell
   - [ ] Test whitespace-only values treated as missing

5. **File Handling Tests (3 tests)**
   - [ ] Test FileNotFoundError for non-existent file
   - [ ] Test OutputParsingError for non-Excel file (.txt)
   - [ ] Test OutputParsingError for corrupted Excel file

6. **Edge Cases (2 tests)**
   - [ ] Test case-insensitive column matching ('TEMA' ‚Üí 'tema')
   - [ ] Test column names with extra whitespace (' periodo ' ‚Üí 'periodo')

**Total: ~14-16 tests m√≠nimo**

### Test Pattern Example

```python
import pytest
from construtor.io import ExcelReader
from construtor.config.exceptions import ValidationError, OutputParsingError

def test_read_valid_excel(temp_excel_file):
    """Test reading valid Excel file returns FocoInput list."""
    # Arrange
    reader = ExcelReader()

    # Act
    focos = reader.read_input(str(temp_excel_file))

    # Assert
    assert len(focos) == 2
    assert focos[0].tema == "Cardiologia"
    assert focos[0].foco == "Insufici√™ncia Card√≠aca"
    assert focos[0].periodo == "3¬∫ ano"

def test_missing_column_raises_validation_error(tmp_path):
    """Test error when required column is missing."""
    # Arrange
    import pandas as pd
    df = pd.DataFrame({
        'tema': ['Cardiologia'],
        'foco': ['ICC'],
        # 'periodo' is MISSING
    })
    file_path = tmp_path / "missing_col.xlsx"
    df.to_excel(file_path, index=False, engine='openpyxl')

    reader = ExcelReader()

    # Act & Assert
    with pytest.raises(ValidationError) as exc_info:
        reader.read_input(str(file_path))

    assert "periodo" in str(exc_info.value).lower()
    assert "missing" in str(exc_info.value).lower()

def test_invalid_periodo_raises_validation_error(tmp_path):
    """Test error for invalid periodo value."""
    # Arrange
    import pandas as pd
    df = pd.DataFrame({
        'tema': ['Cardiologia'],
        'foco': ['ICC'],
        'periodo': ['5¬∫ ano'],  # Invalid!
    })
    file_path = tmp_path / "invalid.xlsx"
    df.to_excel(file_path, index=False, engine='openpyxl')

    reader = ExcelReader()

    # Act & Assert
    with pytest.raises(ValidationError) as exc_info:
        reader.read_input(str(file_path))

    assert "periodo" in str(exc_info.value).lower()
    assert "5¬∫ ano" in str(exc_info.value)

## Previous Story Intelligence (Story 1.4)

### Principais Aprendizados da Implementa√ß√£o da Story 1.4

**‚úÖ Qualidade de C√≥digo Estabelecida:**
- 27 testes criados e 100% passando (Story 1.4 - SQLite persistence)
- Zero erros ruff ap√≥s implementa√ß√£o desde o in√≠cio
- Pattern de commit message estabelecido com Co-Authored-By tag
- `.ruff.toml` configurado e funcional desde Story 1.3

**‚úÖ Patterns T√©cnicos Validados:**
- Exception hierarchy reutilizada com sucesso (PipelineError ‚Üí ValidationError, OutputParsingError)
- Pydantic models funcionam perfeitamente (QuestionRecord com 26 campos)
- Logging estruturado com logger = logging.getLogger(__name__)
- Type hints completos em todos os m√©todos p√∫blicos
- Docstrings no estilo Google (Args/Returns/Raises)

**‚úÖ Arquivos Prontos para Uso:**
- `src/construtor/config/exceptions.py` ‚Üí ValidationError, OutputParsingError dispon√≠veis
- `src/construtor/models/question.py` ‚Üí QuestionRecord, CriadorOutput
- `src/construtor/models/pipeline.py` ‚Üí BatchState
- `src/construtor/metrics/store.py` ‚Üí MetricsStore (para futuro uso com Excel reader)
- `.ruff.toml` ‚Üí Configurado com regras espec√≠ficas

**‚úÖ Li√ß√µes Aprendidas:**
1. **Ruff Early:** Rodar `ruff check` desde o in√≠cio evita ac√∫mulo de warnings
2. **TDD Approach:** Criar testes durante implementa√ß√£o garante melhor cobertura
3. **ClassVar Annotations:** Necess√°rio para constantes de classe (VALID_PERIODOS, REQUIRED_COLUMNS)
4. **Exception Chaining:** Sempre usar `raise ... from err` para preservar stack trace
5. **File List Documentation:** Distinguir CRIADO/MODIFICADO/REUTILIZADO no completion notes
6. **Pytest Fixtures:** Usar fixtures para setup compartilhado (temp files, etc.)

**‚úÖ Padr√µes Estabelecidos para Story 1.5:**
- Usar mesmo pattern de testes: fixtures com temp files
- Seguir mesmo n√≠vel de documenta√ß√£o (docstrings completas)
- Aplicar ruff desde o in√≠cio (n√£o acumular warnings)
- Documentar completion notes durante implementa√ß√£o
- File list deve distinguir CRIADO/MODIFICADO/REUTILIZADO
- Commits com mensagem detalhada + Co-Authored-By tag

**üîó Conex√£o Direta com Story 1.5:**
- ExcelReader precisar√° importar exce√ß√µes: `from construtor.config.exceptions import ValidationError, OutputParsingError`
- Se FocoInput n√£o existe em models/question.py, criar como parte desta story
- Pattern de teste ser√° id√™ntico: pytest fixtures, 100% coverage, ruff zero warnings
- Valida√ß√£o de dados segue mesmo rigor que valida√ß√£o SQLite (explicit error messages)
- Logging pattern id√™ntico: logger.info() para sucesso, logger.error() para falhas

**‚ö†Ô∏è Aten√ß√£o Especial:**

Story 1.4 usou transa√ß√µes at√¥micas para garantir integridade de dados. Story 1.5 deve ter o mesmo rigor na valida√ß√£o de entrada:
- N√£o aceitar dados parcialmente v√°lidos
- Falhar r√°pido com mensagens claras
- Logar contexto completo (file path, row numbers, column names)

## Git Intelligence Summary

### An√°lise dos Commits Recentes

**Commit dc51d38 (Mais Recente - Story 1.4 com corrections):**
```
feat: implementar persist√™ncia SQLite com code review corrections

Implementa√ß√£o completa:
- MetricsStore com 5 tabelas (27 testes, 100% passing)
- WAL mode + transa√ß√µes at√¥micas
- Code review corrections aplicadas

Qualidade validada:
- Ruff check: 0 warnings
- Pytest: 100% passing
```

**Commit 1accb91 (Story 1.3 - LLM Providers):**
```
feat: implementar abstra√ß√£o de provedores LLM com qualidade de c√≥digo

Arquivos criados/modificados:
- .ruff.toml (CRIADO)
- src/construtor/providers/ (CRIADO - 3 files)
- tests/test_providers/ (CRIADO - 54 tests)
```

**Commit d0e53ba (Story 1.2 - Pydantic Models):**
```
feat: implementar modelos Pydantic de dados para pipeline de quest√µes

Arquivos criados:
- src/construtor/models/ (4 modules, 41 testes)
```

**Padr√µes Identificados:**

1. **Estrutura de Commit:** Mensagem detalhada com bullet points + Co-Authored-By tag
2. **Organiza√ß√£o de Arquivos:** Criar m√≥dulo completo por vez (implementation + tests + exports)
3. **Test Coverage:** M√≠nimo 11+ testes por story, 100% passing antes de commit
4. **Story Updates:** Story markdown file sempre atualizado com status e completion notes
5. **Conven√ß√µes de C√≥digo:** PEP 8 rigorosamente seguido, validado por ruff

### Insights Acion√°veis para Story 1.5

**1. Estrutura de Diret√≥rio Estabelecida:**
```
src/construtor/io/       ‚Üê Story 1.5 vai aqui
‚îú‚îÄ‚îÄ __init__.py          ‚Üê Exportar ExcelReader
‚îî‚îÄ‚îÄ excel_reader.py      ‚Üê Implementa√ß√£o completa
```

**2. Pattern de Depend√™ncias:**
- Story 1.5 pode importar de `construtor.config.exceptions` (ValidationError, OutputParsingError)
- Story 1.5 pode importar de `construtor.models.question` (FocoInput - criar se n√£o existe)
- pandas + openpyxl j√° instalados (Story 1.1)

**3. Conven√ß√µes de C√≥digo:**
- Seguir PEP 8 rigorosamente (validado por ruff)
- Docstrings completas em estilo Google
- Type hints em TODOS os m√©todos p√∫blicos
- ClassVar para constantes de classe (VALID_PERIODOS, REQUIRED_COLUMNS)

**4. Testing Strategy:**
- Criar tests/test_io/test_excel_reader.py
- Usar pytest fixtures (temp_excel_file, invalid_excel_file)
- M√≠nimo 14+ testes (baseado em an√°lise de cobertura)
- Validar com `uv run pytest tests/test_io/` antes de commit

**5. Commit Message Template:**
```
feat: implementar leitor de Excel de input com valida√ß√£o completa

Implementa ExcelReader para importar temas, focos e per√≠odos:
- Leitura com pandas 3.0 + openpyxl 3.1.5 engine
- Valida√ß√£o de colunas obrigat√≥rias (tema, foco, periodo)
- Valida√ß√£o de per√≠odo acad√™mico (1¬∫-4¬∫ ano apenas)
- Detec√ß√£o de dados faltantes com row numbers
- Convers√£o para FocoInput Pydantic models
- 14+ testes com 100% coverage (todos passando)

Qualidade de c√≥digo:
- Ruff check passa com 0 warnings
- Type hints completos em todos os m√©todos
- Exception handling com ValidationError/OutputParsingError
- Documenta√ß√£o completa com docstrings

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>
```

## Latest Tech Information (2026)

### pandas 3.0.0 (Latest Release - Feb 2026)

**Vers√£o Atual:** pandas 3.0.0 with Apache Arrow backend

**Principais Features para Excel I/O:**
- **Apache Arrow Backend:** Melhoria de performance para grandes datasets (~30% mais r√°pido)
- **Improved Missing Value Handling:** Melhor detec√ß√£o de NaN/NA values
- **Better Type Inference:** dtype=str garante que Excel n√£o converta automaticamente (ex: "1¬∫ ano" ‚Üí n√∫mero)
- **read_excel() Enhancements:** Melhor error handling para arquivos corrompidos

**Critical Parameters (2026):**
```python
df = pd.read_excel(
    "input.xlsx",
    engine='openpyxl',  # REQUIRED for .xlsx in pandas 3.0
    dtype=str,          # Prevent Excel auto-conversion
    na_filter=True,     # Default - detect missing values
    keep_default_na=True,  # Use standard NaN markers
)
```

**Default NaN Values Recognized:**
- Empty cells: `''`
- Excel NA: `'#N/A'`, `'#N/A N/A'`, `'#NA'`
- Common NA: `'N/A'`, `'NA'`, `'NULL'`, `'NaN'`, `'None'`, `'null'`

**Sources:**
- [pandas 3.0.0 Documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html)
- [Python Data Processing 2026: Pandas Deep Dive](https://dev.to/dataformathub/python-data-processing-2026-deep-dive-into-pandas-polars-and-duckdb-2c1)

### openpyxl 3.1.5 (Latest Stable - 2026)

**Vers√£o Atual:** openpyxl 3.1.5

**Requirements:**
- Python 3.8+ (we have 3.11 ‚úÖ)
- Used as pandas backend (no direct import needed for ExcelReader)

**Performance Improvements (vs 3.0.x):**
- 15-20% faster read operations
- Better memory efficiency for large files
- Improved error messages for corrupted Excel files
- Full .xlsx support (not .xls - that's xlrd)

**How pandas Uses openpyxl:**
1. pandas calls `pd.read_excel(engine='openpyxl')`
2. openpyxl loads .xlsx file (ZIP archive with XML)
3. openpyxl parses worksheet XML
4. pandas converts to DataFrame

**When to Import openpyxl Directly:**
- Need cell formatting (bold, colors, borders)
- Need to read charts or images
- Need granular control over Excel structures

**For ExcelReader:** Use pandas with engine='openpyxl' - NO direct openpyxl imports.

**Sources:**
- [openpyxl 3.1.5 Documentation](https://openpyxl.readthedocs.io/en/stable/)
- [Working with Pandas and NumPy - openpyxl](https://openpyxl.readthedocs.io/en/stable/pandas.html)

### Best Practices (2026)

**Pandas vs openpyxl Decision Tree:**

```
Need to read tabular data from Excel?
‚îú‚îÄ YES ‚Üí Use pandas.read_excel(engine='openpyxl')
‚îÇ   ‚îî‚îÄ Fast, simple, integrates with DataFrame
‚îî‚îÄ Need cell formatting/charts/images?
    ‚îî‚îÄ YES ‚Üí Import openpyxl directly
        ‚îî‚îÄ Granular control, slower for data
```

**For Story 1.5:** pandas.read_excel() is perfect choice.

**Excel File Validation:**

Latest pattern (2026) for robust Excel reading:

```python
from pathlib import Path
import pandas as pd
from openpyxl.utils.exceptions import InvalidFileException

def read_excel_safely(file_path: str) -> pd.DataFrame:
    """Read Excel with robust error handling."""
    path = Path(file_path)

    # 1. Check file exists
    if not path.exists():
        raise FileNotFoundError(f"File not found: {file_path}")

    # 2. Check is a file (not directory)
    if not path.is_file():
        raise ValueError(f"Path is not a file: {file_path}")

    # 3. Check extension
    if path.suffix.lower() not in ['.xlsx', '.xlsm']:
        raise ValueError(f"Not an Excel file: {file_path}")

    # 4. Read with pandas + openpyxl
    try:
        df = pd.read_excel(
            file_path,
            engine='openpyxl',
            dtype=str,  # Prevent auto-conversion
        )
        return df
    except InvalidFileException as e:
        raise ValueError(f"Invalid Excel format: {e}") from e
```

**Sources:**
- [Pandas vs Openpyxl Guide - Statology](https://www.statology.org/how-to-effectively-work-with-excel-files-in-python-pandas-vs-openpyxl-guide/)
- [Excel Files: openpyxl and pandas Tutorial](https://krython.com/tutorial/python/excel-files-openpyxl-and-pandas/)

## Project Structure Notes

### Alignment with Unified Project Structure

**100% Compliant with Architecture Document:**
- ‚úÖ Follows [io/ module structure](../../_bmad-output/planning-artifacts/architecture.md#complete-project-directory-structure)
- ‚úÖ Implements [Excel input reading](../../_bmad-output/planning-artifacts/architecture.md#gest√£o-de-input)
- ‚úÖ Uses [ValidationError for data validation](../../_bmad-output/planning-artifacts/architecture.md#process-patterns)
- ‚úÖ Uses [snake_case naming](../../_bmad-output/planning-artifacts/architecture.md#naming-patterns)
- ‚úÖ Implements [Boundary 3: Pipeline ‚Üî IO](../../_bmad-output/planning-artifacts/architecture.md#architectural-boundaries)

**Critical for Future Stories:**
- Story 1.6 (Excel Writer) usar√° mesmo padr√£o pandas + openpyxl para escrita
- Story 2.1 (SubFoco Generator) consome List[FocoInput] produzida aqui
- Story 3.1 (Batch Processor) chama ExcelReader.read_input() para carregar focos
- Todo o pipeline depende de FocoInput bem estruturado desta story

**Detected Conflicts:** Nenhum - implementa√ß√£o greenfield alinhada com arquitetura

### References

**Architecture Documentation:**
- [IO Module Structure](../../_bmad-output/planning-artifacts/architecture.md#complete-project-directory-structure) - Lines 468-473
- [Validation Patterns](../../_bmad-output/planning-artifacts/architecture.md#process-patterns) - Error handling
- [Boundary 3: Pipeline ‚Üî IO](../../_bmad-output/planning-artifacts/architecture.md#architectural-boundaries) - Lines 540-545

**Requirements Documentation:**
- [PRD - Gest√£o de Input](../../_bmad-output/planning-artifacts/prd.md#gest√£o-de-input) - FR1-FR3
- [Epics - Story 1.5](../../_bmad-output/planning-artifacts/epics.md#story-15-implementar-leitor-de-excel-de-input) - Lines 280-299

**Related Stories:**
- [Story 1.1 - Project Init](./1-1-inicializar-projeto-e-estrutura-base.md) - Completada (depend√™ncias instaladas)
- [Story 1.2 - Pydantic Models](./1-2-criar-modelos-pydantic-de-dados.md) - Completada (FocoInput pode estar aqui)
- [Story 1.4 - SQLite Store](./1-4-configurar-sqlite-para-persistencia-de-estado.md) - Completada (exception patterns)
- Story 1.6 - Excel Writer (bloqueada por esta story - usa mesmo padr√£o pandas/openpyxl)
- Story 2.1 - SubFoco Generator (bloqueada por esta story - consome FocoInput)

## Dev Agent Record

### Agent Model Used

Claude Sonnet 4.5 (claude-sonnet-4-5-20250929)

### Debug Log References

N/A - Implementation completed without major issues

### Completion Notes List

‚úÖ **Story 1.5 Implementation Completed - 2026-02-07**

**Implemented Features:**
- ‚úÖ FocoInput Pydantic model with strict validation, campo validators, and Literal type for periodo
- ‚úÖ ExcelReader class with pandas 3.0 + openpyxl 3.1.5 backend
- ‚úÖ Comprehensive column validation (case-insensitive, whitespace handling)
- ‚úÖ Periodo validation (only 1¬∫-4¬∫ ano accepted)
- ‚úÖ Missing data detection (NaN values and whitespace-only)
- ‚úÖ DataFrame to Pydantic conversion with row-level error tracking
- ‚úÖ Comprehensive error handling (FileNotFoundError, ValidationError, OutputParsingError)
- ‚úÖ Structured logging with logger.info/logger.exception
- ‚úÖ ValidationError exception added to exceptions hierarchy

**Testing:**
- ‚úÖ 16 comprehensive tests created (exceeds 14+ requirement)
- ‚úÖ All 147 project tests passing (16 new + 131 existing)
- ‚úÖ Test categories: Happy Path (3), Column Validation (4), Periodo Validation (1), Missing Data (2), File Handling (3), Edge Cases (3)
- ‚úÖ Fixtures created for all test scenarios

**Code Quality:**
- ‚úÖ Ruff check: 0 warnings (all files pass)
- ‚úÖ Ruff format: All code properly formatted
- ‚úÖ Type hints: Complete on all public methods
- ‚úÖ Docstrings: Google style with Args/Returns/Raises
- ‚úÖ ClassVar annotations: Used for REQUIRED_COLUMNS and VALID_PERIODOS

**Architecture Compliance:**
- ‚úÖ Follows snake_case naming conventions
- ‚úÖ Uses custom exception hierarchy (ValidationError, OutputParsingError)
- ‚úÖ Structured logging pattern (logger.info for success, logger.exception in exception handlers)
- ‚úÖ Pydantic models with ConfigDict(strict=True)
- ‚úÖ Complete docstrings and type hints

**Additional Notes:**
- ValidationError was added to exceptions.py as it didn't exist before
- Used logging.exception instead of logging.error in exception handlers (TRY400 compliance)
- All data normalization (lowercase, strip whitespace) implemented
- Row numbers reported as Excel-style (1-indexed, +2 for header)

**Code Review Corrections Applied (2026-02-07):**
- ‚úÖ Added usecols=REQUIRED_COLUMNS for performance optimization (only reads needed columns)
- ‚úÖ Added file extension validation (.xlsx/.xlsm only) for clearer error messages
- ‚úÖ Updated test to handle extension validation (test_invalid_excel_format_raises_parsing_error)
- ‚úÖ Added test for corrupted Excel files (test_corrupted_excel_file_raises_parsing_error)
- ‚úÖ Fixed import sorting in test file (ruff I001)
- ‚úÖ Updated File List to include sprint-status.yaml modification
- ‚úÖ Corrected line count documentation (255 lines, 17 tests)

### File List

**CRIADOS:**
- src/construtor/io/excel_reader.py (ExcelReader class - 256 lines)
- tests/test_io/test_excel_reader.py (17 comprehensive tests - 630+ lines)
- tests/test_io/__init__.py (module init)
- tests/test_io/fixtures/ (directory for test Excel files - empty, tests use tmp_path fixtures)

**MODIFICADOS:**
- src/construtor/io/__init__.py (export ExcelReader)
- src/construtor/models/question.py (added FocoInput model with validators)
- src/construtor/config/exceptions.py (added ValidationError exception)
- _bmad-output/implementation-artifacts/sprint-status.yaml (updated story status to 'review')

**REUTILIZADOS:**
- .ruff.toml (lint/format rules)
- src/construtor/config/exceptions.py (OutputParsingError, PipelineError base)

---

**Created:** 2026-02-07
**Epic:** 1 - Funda√ß√£o do Projeto e Infraestrutura Core
**Priority:** CRITICAL - Bloqueia Story 1.6, Story 2.1, Story 3.1, todo o pipeline de gera√ß√£o
**Estimated Effort:** 2-3 horas
```

